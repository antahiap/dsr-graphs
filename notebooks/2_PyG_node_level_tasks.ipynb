{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/antahiap/dsr-graphs/blob/main/notebooks/2_PyG_node_level_tasks.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Please, make a copy of the notebook before we start.\n",
        "# Turn on the GPU support in the Runtime/Change runtime type.\n",
        "import os\n",
        "import torch\n",
        "os.environ['TORCH'] = torch.__version__\n",
        "print(torch.__version__)\n",
        "\n",
        "# Install Pytorch Geometric and its dependencies\n",
        "!pip install -q torch-scatter -f https://data.pyg.org/whl/torch-${TORCH}.html\n",
        "!pip install -q torch-sparse -f https://data.pyg.org/whl/torch-${TORCH}.html\n",
        "!pip install -q git+https://github.com/pyg-team/pytorch_geometric.git\n",
        "\n",
        "# Helper function for visualization.\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.manifold import TSNE\n",
        "\n",
        "def visualize(h, color):\n",
        "    z = TSNE(n_components=2).fit_transform(h.detach().cpu().numpy())\n",
        "\n",
        "    plt.figure(figsize=(10,10))\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "\n",
        "    plt.scatter(z[:, 0], z[:, 1], s=70, c=color, cmap=\"Set2\")\n",
        "    plt.show()\n",
        "\n",
        "def visualize_both(h1, h2, title1, title2, color):\n",
        "    z1 = TSNE(n_components=2).fit_transform(h1.detach().cpu().numpy())\n",
        "    z2 = TSNE(n_components=2).fit_transform(h2.detach().cpu().numpy())\n",
        "\n",
        "    fig, ax = plt.subplots(1, 2, figsize=(20, 10))\n",
        "\n",
        "    ax[0].scatter(z1[:, 0], z1[:, 1], s=70, c=color, cmap=\"Set2\")\n",
        "    ax[0].set_title(title1)\n",
        "    ax[0].set_xticks([])\n",
        "    ax[0].set_yticks([])\n",
        "\n",
        "    ax[1].scatter(z2[:, 0], z2[:, 1], s=70, c=color, cmap=\"Set2\")\n",
        "    ax[1].set_title(title2)\n",
        "    ax[1].set_xticks([])\n",
        "    ax[1].set_yticks([])\n",
        "\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "Ha6zi-jELFhG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "47ae4af9-e4e7-43ae-e22c-4d74b34b67bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.0.1+cu118\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.2/10.2 MB\u001b[0m \u001b[31m66.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.8/4.8 MB\u001b[0m \u001b[31m47.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for torch_geometric (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Transductive & Inductive learning on graphs**\n",
        "\n",
        ">\"[Transductive inference](https://en.wikipedia.org/wiki/Transduction_(machine_learning)) is reasoning from observed, specific (training) cases to specific (test) cases.\" \\\n",
        ">Inductive inference \"is reasoning from observed training cases to general rules, which are then applied to the test cases.\"\n",
        "\n",
        "What does it actually mean?\n",
        "\n",
        "\n",
        "<center width=\"100%\" style=\"padding:10px\"> <img src =\"https://drive.google.com/uc?id=1IkDcHZ9x0mdBsiFiLjHlgoykThitQyMi\" width=\"600px\"></center>\n",
        "\n",
        "\n",
        "Inductive inference  | Transductive inference\n",
        "-------------------|------------------\n",
        "Train the model and label unlabelled points which we **have never encountered**. | Train the model and label unlabelled points which we **have already encountered**.\n",
        "**Use the initially trained model** for prediction of new unlabelled points. | **Retrain the model** to predict new unlabelled points.\n",
        "Can predict **any point** in the feature space. | Can predict **only the points encountered in the test dataset**.\n",
        "**Less** computational costs. | Can become **more** computationally costly.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "x7n8JB_1s_X-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **GCN layer revisited**\n",
        "\n",
        "Let's have a look at the GCN layer one more time:\n",
        "* $\\hat A = A + I$ - sum of the adjacency matrix and an identity matrix. $\\hat A \\in R^{N \\times N}$\n",
        "* $\\hat D$ - a diagonal node degree matrix of $\\hat A$.\n",
        "\n",
        "$$H^{l+1} = \\sigma\\left(\\hat{D}^{-1/2}\\hat{A}\\hat{D}^{-1/2}H^{l}W^{l}\\right)$$\n",
        "\n",
        "**The adjacency matrix is inside the formula of the update rule!**\n",
        "\n",
        "**<font color='red'>The nature of the GCN layer is that it only* works in the transductive setting.</font>**\n",
        "\n",
        "Consequences:\n",
        "\n",
        "*   It's impossible to classify a newly added node without retraining the model, since the size of the adjacency matrix would change.\n",
        "*   Even if we use the trained model with the graph of the same size the predictions would be meaningless, since the adjacency matrix would contain different entries.\n",
        "\n",
        "**What do we need to do to be able to use a trained model with a completely different graph?**\n",
        "\n",
        "*   Implement the GCN layer in a form that allows to use inductive learning**. (Check PyG implementations).\n",
        "*   Use differrent algorithms, e.g. [generalized message passing algorithm from DeepMind](https://arxiv.org/abs/1806.01261). We will do it in the next colab.\n",
        "\n",
        "\n",
        "\\* It depends on the implementation. PyG implementation allows it to work in the inductive setting out of the box. \\\n",
        "\\** It's not guaranteed that the results on the unseen data would be any good because of the nature of graph convolutions that can be represented as polynomial functions of the adjacency matrix. Explanations: [Graph Representation Learing: Chapter 7](https://www.cs.mcgill.ca/~wlh/grl_book/)"
      ],
      "metadata": {
        "id": "t3wTVqZUtagw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **PyTorch Geometric: Introduction via Node Classification**\n",
        "\n",
        "*   Implementing GNNs with an adjacency matrix is simple and straightforward but can be computationally expensive for large graphs.\n",
        "*   **[PyTorch Geometric (PyG) library](https://github.com/rusty1s/pytorch_geometric)** is an extension to PyTorch, and consists of various methods and utilities for optimized and easy implementation of GNNs.\n",
        "\n",
        "#### **Dataset**\n",
        "PyTorch Geometric provides an easy access to the dataset via the [`torch_geometric.datasets`](https://pytorch-geometric.readthedocs.io/en/latest/modules/datasets.html#torch_geometric.datasets) subpackage."
      ],
      "metadata": {
        "id": "xQ7OGFmQ92-w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch_geometric.datasets import Planetoid\n",
        "\n",
        "dataset = Planetoid(root='data/Planetoid', name='Cora')\n",
        "print(f'Dataset: {dataset}:')\n",
        "print('=========================')\n",
        "print(f'Number of graphs: {len(dataset)}')\n",
        "print(f'Number of features: {dataset.num_features}')\n",
        "print(f'Number of classes: {dataset.num_classes}')"
      ],
      "metadata": {
        "id": "VrwFyJ6_jlJJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "We will use `Cora` dataset, which is a **citation network** where nodes represent documents. Each node is described by a 1433-dimensional bag-of-words feature vector. Two documents are connected if there exists a citation link between them."
      ],
      "metadata": {
        "id": "_TXcjtsOiWGk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can extract the first (and the only) graph, represented by PyG class [Data](https://pytorch-geometric.readthedocs.io/en/latest/modules/data.html#torch_geometric.data.Data), from the dataset object and gather some statistics about it."
      ],
      "metadata": {
        "id": "xCuanzjKJWtg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = dataset[0]  # Get the first graph object.\n",
        "\n",
        "print(data)\n",
        "print('==============================================================')\n",
        "\n",
        "# Gather some statistics about the graph.\n",
        "print(f'Number of nodes: {data.num_nodes}')\n",
        "print(f'Number of edges: {data.num_edges}')\n",
        "print(f'Average node degree: {(data.num_edges) / (2 * data.num_nodes):.2f}')\n",
        "print(f'Number of training nodes: {data.train_mask.sum()}')\n",
        "print(f'Training node label rate: {int(data.train_mask.sum()) / data.num_nodes:.2f}')\n",
        "print(f'Contains isolated nodes: {data.has_isolated_nodes()}')\n",
        "print(f'Contains self-loops: {data.has_self_loops()}')\n",
        "print(f'Is undirected: {data.is_undirected()}')"
      ],
      "metadata": {
        "id": "E4RPd-cxjoX_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The `train_mask`, `val_mask`, and `test_mask` are boolean masks that indicate which nodes we should use for training, validation, and testing"
      ],
      "metadata": {
        "id": "aOmi2vjJjl9I"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Edge index**\n",
        "\n",
        "*   We represent node connectivity via the `edge_index` tensor.\n",
        "*   Printing its transposed version shows us the edges between nodes, e.g. $[0, 633]$ means that there's an edge between node $0$ and node $633$.\n",
        "*   The edge is shown twice for an undirected graph, but the positions of its values are switched, e.g. $[633, 0]$.\n",
        "*   If a graph is directed, then there is an edge only one edge corresponding to each edge direction, e.g. $[0, 633]$ **only**."
      ],
      "metadata": {
        "id": "vNhu89cYOYo2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Javascript  # Restrict height of output cell.\n",
        "\n",
        "display(Javascript('''google.colab.output.setIframeHeight(0, true, {maxHeight: 300})'''))\n",
        "edge_index = data.edge_index\n",
        "print(edge_index.t()[:100])"
      ],
      "metadata": {
        "id": "Eegy1nNrjwpF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This representation is known as the **COO format (coordinate format)** commonly used for representing sparse matrices."
      ],
      "metadata": {
        "id": "Qs3cI2nxi1a1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Node classification**\n",
        "\n",
        "The task is to infer the category of each document (7 in total), having only a small fraction, 5%, of labeled nodes in the training set.\n",
        "\n",
        "Let's create an MLP baseline that is applied to each node independently. This way we can verify whether adding the graph information to the model indeed improves the prediction or not. However, it might also be that the features per node are already expressive enough to clearly point towards a specific class.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "--ARxyUuh14K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.nn import Linear, Dropout, ReLU\n",
        "\n",
        "class MLP(torch.nn.Module):\n",
        "    def __init__(self, c_in, c_out, c_hidden):\n",
        "        super().__init__()\n",
        "        torch.manual_seed(12345)\n",
        "        self.lin1 = Linear(c_in, c_hidden)\n",
        "        self.lin2 = Linear(c_hidden, c_out)\n",
        "        self.dropout = Dropout(p=0.5, inplace=False)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.lin1(x)\n",
        "        x = ReLU()(x)\n",
        "        x = self.dropout(x)\n",
        "        return self.lin2(x)\n",
        "\n",
        "c_in = dataset.num_features\n",
        "c_out = dataset.num_classes\n",
        "model = MLP(c_in=c_in, c_out=c_out, c_hidden=16)\n",
        "print(model)"
      ],
      "metadata": {
        "id": "TYCkstznj7og"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can visualize the 7-dimensional node embeddings that out untrained model produces, using the [TSNE](https://scikit-learn.org/stable/modules/generated/sklearn.manifold.TSNE.html) package that projects a high-dimensional data onto a low-dimensional plane in such a way that similar points are put close to each other."
      ],
      "metadata": {
        "id": "IKGzcBNnQPSo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "\n",
        "out = model(data.x)\n",
        "visualize(out, color=data.y)"
      ],
      "metadata": {
        "id": "tldZeqWrj9fE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**As expected, the untrained model fails to separate the classes and produces similar embeddings for all 7 paper categories.**"
      ],
      "metadata": {
        "id": "w_gJOcRadwkn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's train the MLP model:"
      ],
      "metadata": {
        "id": "tosl_RLocw__"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Javascript  # Restrict height of output cell.\n",
        "display(Javascript('''google.colab.output.setIframeHeight(0, true, {maxHeight: 300})'''))\n",
        "\n",
        "#TODO: train MLP\n"
      ],
      "metadata": {
        "id": "mvE4bcaXQmLs",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "e134c8aa-cda3-425f-911d-60ebf5ca2e8f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "google.colab.output.setIframeHeight(0, true, {maxHeight: 300})"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Reasons for poor MLP performance**\n",
        "\n",
        "*   **Strong overfitting** due to only having access to a **small amount of training nodes**, that leads to poor generalization on the unseen nodes.\n",
        "*   It also fails to incorporate an important inductive bias into the model: **Papers belonging to the same category are most likely to have a citation relation (edge) between them** $\\to$ we can use a GNN to incorporate this information."
      ],
      "metadata": {
        "id": "YD5FexFEZV2H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch_geometric.nn import GCNConv\n",
        "\n",
        "class GCN(torch.nn.Module):\n",
        "    def __init__(self, c_in, c_out, c_hidden):\n",
        "    pass\n"
      ],
      "metadata": {
        "id": "6A37aNGfXB1a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142
        },
        "outputId": "612a4086-c64c-4bec-ea2f-8e3a74ba79ff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndentationError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-1-d52c77a99319>\"\u001b[0;36m, line \u001b[0;32m5\u001b[0m\n\u001b[0;31m    pass\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block after function definition on line 4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Exercise 2.1: MLP vs GCN untrained embeddings**\n",
        "\n",
        "*   Create two new models, MLP and GCN, i.e. instances of the corresponding classes, using the same number of input/hidden/output channels. Please, use `c_hidden=256` for both models and name a new MLP model differently, so the trained model stays untouched, we will need it for later.\n",
        "*   Following the example above, plot the lower dimensional representation of the node embeddings produced by the both models.\n",
        "  - **hint:** don't forget to set the models to the evaluation mode. This will turn the dropout off.\n",
        "  - **hint:** make use of the function `visualize_both` defined in the imports.\n",
        "* Answer the following questions:\n",
        "  - What is the difference between the embeddings?\n",
        "  - Why do you think this difference exists?\n",
        "  - What conclusions about GCNs can you draw?\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "_wD11CQq2xNr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **[The Weisfeiler-Lehman Isomorphism Test](https://davidbieber.com/post/2019-05-10-weisfeiler-lehman-isomorphism-test/)**\n",
        "\n",
        "<center width=\"100%\" style=\"padding:10px\"> <img src =\"https://drive.google.com/uc?id=1ar2xbg4lz0_-AjkT0Ic2EEHZKyXl2Mjl\" width=\"600px\"></center>\n",
        "\n",
        "> \"*Two graphs are considered isomorphic if there is a mapping between the nodes of the graphs that preserves node adjacencies.*\"\n",
        "\n",
        "**Algorithm:**\n",
        "\n",
        "1.   Intialize all nodes features to 1.\n",
        "2.   Get features $\\{ h_{v_j} \\}$ of neighboring nodes $\\{ v_j \\}$\n",
        "3.   Update node feature $h_{v_i} \\leftarrow \\text{hash} (\\sum_j h_{v_j})$\n",
        "4.   Partition the nodes in the graph by their features. Repeat 2 + 3 for up to  (the number of nodes) iterations, or until there is no change in the partition of nodes by features from one iteration to the next.\n",
        "\n",
        "If the partitions of two graphs are the same, then the graphs can be isomorphic.\n",
        "\n",
        "*   Graph Convolutional layer-wise propagation rule in vector form:\n",
        "$$h_{v_i}^{(l+1)} = \\sigma (\\sum_j \\frac{1}{c_{ij}}  h_{v_j}^{(l)} W^{(l)}),$$\n",
        "where $c_{ij}$ is a normalization constant for the edge.\n",
        "\n",
        "*  The propagation rule can be interpreted as a differentiable and parametrized (with W(l)) variant of the hash function used in the Weisfeiler-Lehman algorithm.\n",
        "\n",
        "**We get meaningful smooth embeddings where we can interpret distance as (dis-)similarity of local graph structures!**\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "GNgRgIHNyOMl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Exercise 2.2: Train and visualize GCN**\n",
        "\n",
        "*   Write code for training the GCN model.\n",
        "  - **hint:** Modify the code for MLP training so that it runs with the GCN model.\n",
        "  - **hint:** Use the same number of hidden channels.\n",
        "*   Compare the results of the GCN and MLP.\n",
        "*   Visualize trained embeddings of MLP and GCN.\n",
        "  - **hint:** You can reuse the code from Exercise 2.1, you just need to use the trained models. Don't forget to set them to the eval mode.\n",
        "\n"
      ],
      "metadata": {
        "id": "A6mX6zFuoZGt"
      }
    }
  ]
}